% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})



@article{2018OpenPose,
  title={OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  author={ Cao, Zhe  and  Hidalgo, Gines  and  Simon, Tomas  and  Wei, Shih En  and  Sheikh, Yaser },
  journal={IEEE TPAMI},
  year={2018}
}

@inproceedings{fang2017rmpe,
  title={Rmpe: Regional multi-person pose estimation},
  author={Fang, Hao-Shu and Xie, Shuqin and Tai, Yu-Wing and Lu, Cewu},
  booktitle={ICCV},
  pages={2334--2343},
  year={2017}
}

@inproceedings{xu2020deep,
  title={Deep kinematics analysis for monocular 3d human pose estimation},
  author={Xu, Jingwei and Yu, Zhenbo and Ni, Bingbing and Yang, Jiancheng and Yang, Xiaokang and Zhang, Wenjun},
  booktitle={CVPR},
  pages={899--908},
  year={2020}
}

@inproceedings{chen2021channel,
  title={Channel-wise topology refinement graph convolution for skeleton-based action recognition},
  author={Chen, Yuxin and Zhang, Ziqi and Yuan, Chunfeng and Li, Bing and Deng, Ying and Hu, Weiming},
  booktitle={ICCV},
  pages={13359--13368},
  year={2021}
}

@inproceedings{cheng2020skeleton,
  title={Skeleton-based action recognition with shift graph convolutional network},
  author={Cheng, Ke and Zhang, Yifan and He, Xiangyu and Chen, Weihan and Cheng, Jian and Lu, Hanqing},
  booktitle={CVPR},
  pages={183--192},
  year={2020}
}

@inproceedings{du2015hierarchical,
  title={Hierarchical recurrent neural network for skeleton based action recognition},
  author={Du, Yong and Wang, Wei and Wang, Liang},
  booktitle={CVPR},
  pages={1110--1118},
  year={2015}
}

@inproceedings{ke2017new,
  title={A new representation of skeleton sequences for 3d action recognition},
  author={Ke, Qiuhong and Bennamoun, Mohammed and An, Senjian and Sohel, Ferdous and Boussaid, Farid},
  booktitle={CVPR},
  pages={3288--3297},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={NeurIPS},
  volume={30},
  year={2017}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={ICCV},
  pages={10012--10022},
  year={2021}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@inproceedings{lin2020ms2l,
  title={Ms2l: Multi-task self-supervised learning for skeleton based action recognition},
  author={Lin, Lilang and Song, Sijie and Yang, Wenhan and Liu, Jiaying},
  booktitle={ACM MM},
  pages={2490--2498},
  year={2020}
}

@inproceedings{nie2020unsupervised,
  title={Unsupervised 3d human pose representation with viewpoint and pose disentanglement},
  author={Nie, Qiang and Liu, Ziwei and Liu, Yunhui},
  booktitle={ECCV},
  pages={102--118},
  year={2020},
  organization={Springer}
}

@inproceedings{su2020predict,
  title={Predict \& cluster: Unsupervised skeleton based action recognition},
  author={Su, Kun and Liu, Xiulong and Shlizerman, Eli},
  booktitle={CVPR},
  pages={9631--9640},
  year={2020}
}

@inproceedings{zheng2018unsupervised,
  title={Unsupervised representation learning with long-term dynamics for skeleton based action recognition},
  author={Zheng, Nenggan and Wen, Jun and Liu, Risheng and Long, Liangqu and Dai, Jianhua and Gong, Zhefeng},
  booktitle={AAAI},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={CVPR},
  pages={9729--9738},
  year={2020}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={NeurIPS},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@article{rao2021augmented,
  title={Augmented skeleton based contrastive action learning with momentum lstm for unsupervised action recognition},
  author={Rao, Haocong and Xu, Shihao and Hu, Xiping and Cheng, Jun and Hu, Bin},
  journal={Information Sciences},
  volume={569},
  pages={90--109},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{guo2022contrastive,
  title={Contrastive learning from extremely augmented skeleton sequences for self-supervised action recognition},
  author={Guo, Tianyu and Liu, Hong and Chen, Zhan and Liu, Mengyuan and Wang, Tao and Ding, Runwei},
  booktitle={AAAI},
  volume={36},
  number={1},
  pages={762--770},
  year={2022}
}

@inproceedings{moliner2022bootstrapped,
  title={Bootstrapped representation learning for skeleton-based action recognition},
  author={Moliner, Olivier and Huang, Sangxia and {\AA}str{\"o}m, Kalle},
  booktitle={CVPR},
  pages={4154--4164},
  year={2022}
}

@inproceedings{lin2023actionlet,
  title={Actionlet-Dependent Contrastive Learning for Unsupervised Skeleton-Based Action Recognition},
  author={Lin, Lilang and Zhang, Jiahang and Liu, Jiaying},
  booktitle={CVPR},
  pages={2363--2372},
  year={2023}
}

@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}

@article{zhou2021ibot,
  title={ibot: Image bert pre-training with online tokenizer},
  author={Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao},
  journal={arXiv preprint arXiv:2111.07832},
  year={2021}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  pages={16000--16009},
  year={2022}
}

@inproceedings{xie2022simmim,
  title={Simmim: A simple framework for masked image modeling},
  author={Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han},
  booktitle={CVPR},
  pages={9653--9663},
  year={2022}
}

@inproceedings{yan2023skeletonmae,
  title={Skeletonmae: graph-based masked autoencoder for skeleton sequence pre-training},
  author={Yan, Hong and Liu, Yang and Wei, Yushen and Li, Zhen and Li, Guanbin and Lin, Liang},
  booktitle={ICCV},
  pages={5606--5618},
  year={2023}
}

@inproceedings{wu2023skeletonmae,
  title={Skeletonmae: Spatial-temporal masked autoencoders for self-supervised skeleton action recognition},
  author={Wu, Wenhan and Hua, Yilei and Zheng, Ce and Wu, Shiqian and Chen, Chen and Lu, Aidong},
  booktitle={2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)},
  pages={224--229},
  year={2023},
  organization={IEEE}
}

@inproceedings{mao2023masked,
  title={Masked Motion Predictors are Strong 3D Action Representation Learners},
  author={Mao, Yunyao and Deng, Jiajun and Zhou, Wengang and Fang, Yao and Ouyang, Wanli and Li, Houqiang},
  booktitle={ICCV},
  pages={10181--10191},
  year={2023}
}

@inproceedings{baevski2022data2vec,
  title={Data2vec: A general framework for self-supervised learning in speech, vision and language},
  author={Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  booktitle={International Conference on Machine Learning},
  pages={1298--1312},
  year={2022},
  organization={PMLR}
}

@inproceedings{baevski2023efficient,
  title={Efficient self-supervised learning with contextualized target representations for vision, speech and language},
  author={Baevski, Alexei and Babu, Arun and Hsu, Wei-Ning and Auli, Michael},
  booktitle={International Conference on Machine Learning},
  pages={1416--1429},
  year={2023},
  organization={PMLR}
}

@inproceedings{ding2017investigation,
  title={Investigation of different skeleton features for cnn-based 3d action recognition},
  author={Ding, Zewei and Wang, Pichao and Ogunbona, Philip O and Li, Wanqing},
  booktitle={2017 IEEE International conference on multimedia \& expo workshops (ICMEW)},
  pages={617--622},
  year={2017},
  organization={IEEE}
}

@inproceedings{liu2016spatio,
  title={Spatio-temporal lstm with trust gates for 3d human action recognition},
  author={Liu, Jun and Shahroudy, Amir and Xu, Dong and Wang, Gang},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part III 14},
  pages={816--833},
  year={2016},
  organization={Springer}
}

@inproceedings{zhang2017view,
  title={View adaptive recurrent neural networks for high performance human action recognition from skeleton data},
  author={Zhang, Pengfei and Lan, Cuiling and Xing, Junliang and Zeng, Wenjun and Xue, Jianru and Zheng, Nanning},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2117--2126},
  year={2017}
}

@inproceedings{yan2018spatial,
  title={Spatial temporal graph convolutional networks for skeleton-based action recognition},
  author={Yan, Sijie and Xiong, Yuanjun and Lin, Dahua},
  booktitle={AAAI},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{zhang2020semantics,
  title={Semantics-guided neural networks for efficient skeleton-based human action recognition},
  author={Zhang, Pengfei and Lan, Cuiling and Zeng, Wenjun and Xing, Junliang and Xue, Jianru and Zheng, Nanning},
  booktitle={CVPR},
  pages={1112--1121},
  year={2020}
}

@inproceedings{chi2022infogcn,
  title={Infogcn: Representation learning for human skeleton-based action recognition},
  author={Chi, Hyung-gun and Ha, Myoung Hoon and Chi, Seunggeun and Lee, Sang Wan and Huang, Qixing and Ramani, Karthik},
  booktitle={CVPR},
  pages={20186--20196},
  year={2022}
}

@inproceedings{duan2022revisiting,
  title={Revisiting skeleton-based action recognition},
  author={Duan, Haodong and Zhao, Yue and Chen, Kai and Lin, Dahua and Dai, Bo},
  booktitle={CVPR},
  pages={2969--2978},
  year={2022}
}

@inproceedings{du2015skeleton,
  title={Skeleton based action recognition with convolutional neural network},
  author={Du, Yong and Fu, Yun and Wang, Liang},
  booktitle={2015 3rd IAPR Asian conference on pattern recognition (ACPR)},
  pages={579--583},
  year={2015},
  organization={IEEE}
}

@inproceedings{li2017skeleton,
  title={Skeleton-based action recognition with convolutional neural networks},
  author={Li, Chao and Zhong, Qiaoyong and Xie, Di and Pu, Shiliang},
  booktitle={2017 IEEE international conference on multimedia \& expo workshops (ICMEW)},
  pages={597--600},
  year={2017},
  organization={IEEE}
}

@article{shi2020skeleton,
  title={Skeleton-based action recognition with multi-stream adaptive graph convolutional networks},
  author={Shi, Lei and Zhang, Yifan and Cheng, Jian and Lu, Hanqing},
  journal={IEEE TIP},
  volume={29},
  pages={9532--9545},
  year={2020},
  publisher={IEEE}
}

@article{qiu2022spatio,
  title={Spatio-temporal tuples transformer for skeleton-based action recognition},
  author={Qiu, Helei and Hou, Biao and Ren, Bo and Zhang, Xiaohua},
  journal={arXiv preprint arXiv:2201.02849},
  year={2022}
}

@article{plizzari2021skeleton,
  title={Skeleton-based action recognition via spatial and temporal transformer networks},
  author={Plizzari, Chiara and Cannici, Marco and Matteucci, Matteo},
  journal={Computer Vision and Image Understanding},
  volume={208},
  pages={103219},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{shi2020decoupled,
  title={Decoupled spatial-temporal attention network for skeleton-based action-gesture recognition},
  author={Shi, Lei and Zhang, Yifan and Cheng, Jian and Lu, Hanqing},
  booktitle={ACCV},
  year={2020}
}

@inproceedings{yang2021skeleton,
  title={Skeleton cloud colorization for unsupervised 3d action representation learning},
  author={Yang, Siyuan and Liu, Jun and Lu, Shijian and Er, Meng Hwa and Kot, Alex C},
  booktitle={ICCV},
  pages={13423--13433},
  year={2021}
}

@inproceedings{li20213d,
  title={3d human action representation learning via cross-view consistency pursuit},
  author={Li, Linguo and Wang, Minsi and Ni, Bingbing and Wang, Hang and Yang, Jiancheng and Zhang, Wenjun},
  booktitle={CVPR},
  pages={4741--4750},
  year={2021}
}

@inproceedings{wei2022masked,
  title={Masked feature prediction for self-supervised visual pre-training},
  author={Wei, Chen and Fan, Haoqi and Xie, Saining and Wu, Chao-Yuan and Yuille, Alan and Feichtenhofer, Christoph},
  booktitle={CVPR},
  pages={14668--14678},
  year={2022}
}

@inproceedings{dong2023peco,
  title={Peco: Perceptual codebook for bert pre-training of vision transformers},
  author={Dong, Xiaoyi and Bao, Jianmin and Zhang, Ting and Chen, Dongdong and Zhang, Weiming and Yuan, Lu and Chen, Dong and Wen, Fang and Yu, Nenghai and Guo, Baining},
  booktitle={AAAI},
  volume={37},
  number={1},
  pages={552--560},
  year={2023}
}

@article{ulyanov2016instance,
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016}
}

@article{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  journal={NeurIPS},
  volume={35},
  pages={10078--10093},
  year={2022}
}

@inproceedings{shahroudy2016ntu,
  title={Ntu rgb+ d: A large scale dataset for 3d human activity analysis},
  author={Shahroudy, Amir and Liu, Jun and Ng, Tian-Tsong and Wang, Gang},
  booktitle={CVPR},
  pages={1010--1019},
  year={2016}
}

@article{liu2019ntu,
  title={Ntu rgb+ d 120: A large-scale benchmark for 3d human activity understanding},
  author={Liu, Jun and Shahroudy, Amir and Perez, Mauricio and Wang, Gang and Duan, Ling-Yu and Kot, Alex C},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  volume={42},
  number={10},
  pages={2684--2701},
  year={2019},
  publisher={IEEE}
}

@article{liu2017pku,
  title={Pku-mmd: A large scale benchmark for continuous multi-modal human action understanding},
  author={Liu, Chunhui and Hu, Yueyu and Li, Yanghao and Song, Sijie and Liu, Jiaying},
  journal={arXiv preprint arXiv:1703.07475},
  year={2017}
}

@article{duan2022dg,
  title={DG-STGCN: dynamic spatial-temporal modeling for skeleton-based action recognition},
  author={Duan, Haodong and Wang, Jiaqi and Chen, Kai and Lin, Dahua},
  journal={arXiv preprint arXiv:2210.05895},
  year={2022}
}

@inproceedings{kim2022global,
  title={Global-local motion transformer for unsupervised skeleton-based action learning},
  author={Kim, Boeun and Chang, Hyung Jin and Kim, Jungho and Choi, Jin Young},
  booktitle={ECCV},
  pages={209--225},
  year={2022},
  organization={Springer}
}

@inproceedings{thoker2021skeleton,
  title={Skeleton-contrastive 3D action representation learning},
  author={Thoker, Fida Mohammad and Doughty, Hazel and Snoek, Cees GM},
  booktitle={ACM MM},
  pages={1655--1663},
  year={2021}
}

@inproceedings{zhang2022contrastive,
  title={Contrastive positive mining for unsupervised 3d action representation learning},
  author={Zhang, Haoyuan and Hou, Yonghong and Zhang, Wenjing and Li, Wanqing},
  booktitle={ECCV},
  pages={36--51},
  year={2022},
  organization={Springer}
}

@inproceedings{Zhou2023SelfsupervisedAR,
  title={Self-supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences},
  author={Yujie Zhou and Haodong Duan and Anyi Rao and Bing Su and Jiaqi Wang},
  booktitle={AAAI},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:257019654}
}

@inproceedings{
  franco2023hyperbolic,
  title={Hyperbolic Self-paced Learning for Self-supervised Skeleton-based Action Representations},
  author={Luca Franco and Paolo Mandica and Bharti Munjal and Fabio Galasso},
  booktitle={Int. Conf. Learn. Represent.},
  year={2023},
  url={https://openreview.net/forum?id=3Bh6sRPKS3J}
}

@inproceedings{mao2022cmd,
  title={Cmd: Self-supervised 3d action representation learning with cross-modal mutual distillation},
  author={Mao, Yunyao and Zhou, Wengang and Lu, Zhenbo and Deng, Jiajun and Li, Houqiang},
  booktitle={ECCV},
  pages={734--752},
  year={2022},
  organization={Springer}
}

@inproceedings{zhu2023modeling,
  title={Modeling the Relative Visual Tempo for Self-supervised Skeleton-based Action Recognition},
  author={Zhu, Yisheng and Han, Hu and Yu, Zhengtao and Liu, Guangcan},
  booktitle={ICCV},
  pages={13913--13922},
  year={2023}
}

@inproceedings{shah2023halp,
  title={HaLP: Hallucinating Latent Positives for Skeleton-based Self-Supervised Learning of Actions},
  author={Shah, Anshul and Roy, Aniket and Shah, Ketul and Mishra, Shlok and Jacobs, David and Cherian, Anoop and Chellappa, Rama},
  booktitle={CVPR},
  pages={18846--18856},
  year={2023}
}

@inproceedings{zhang2023hierarchical,
  title={Hierarchical consistent contrastive learning for skeleton-based action recognition with growing augmentations},
  author={Zhang, Jiahang and Lin, Lilang and Liu, Jiaying},
  booktitle={AAAI},
  volume={37},
  number={3},
  pages={3427--3435},
  year={2023}
}

@inproceedings{Hua2023SkeAttnCLR,
  Title= {Part Aware Contrastive Learning for Self-Supervised Action Recognition},
  Author= {Hua, Yilei and Wu, Wenhan and Zheng, Ce and Lu, Aidong and Liu, Mengyuan and Chen, Chen and Wu, Shiqian},
  Booktitle= {Int. J. Comput. Vis.},
  Year= {2023}
}

@inproceedings{hico2023,
  title={Hierarchical Contrast for Unsupervised Skeleton-based Action Representation Learning},
  author={Jianfeng Dong and Shengkai Sun and Zhonglin Liu and Shujie Chen and Baolong Liu and Xun Wang},
  booktitle={AAAI},
  year={2023}
}

@inproceedings{zhu2023motionbert,
  title={MotionBERT: A Unified Perspective on Learning Human Motion Representations},
  author={Zhu, Wentao and Ma, Xiaoxuan and Liu, Zhaoyang and Liu, Libin and Wu, Wayne and Wang, Yizhou},
  booktitle={ICCV},
  pages={15085--15099},
  year={2023}
}

@inproceedings{chen2022hierarchically,
  title={Hierarchically self-supervised transformer for human skeleton representation learning},
  author={Chen, Yuxiao and Zhao, Long and Yuan, Jianbo and Tian, Yu and Xia, Zhaoyang and Geng, Shijie and Han, Ligong and Metaxas, Dimitris N},
  booktitle={ECCV},
  pages={185--202},
  year={2022},
  organization={Springer}
}