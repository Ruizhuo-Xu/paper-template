\vspace{-5pt}
\section{Conclusion}
\vspace{-5pt}
In this work, we propose Skeleton2vec, a novel self-supervised learning framework
for 3D skeleton-based action recognition. We demonstrated the superiority of utilizing
global contextualized representations built by a teacher model as the prediction target
for the masked prediction task, compared to isolated raw joints or temporal motion with
local context. Furthermore, considering the high spatiotemporal correlation in skeleton
sequences, we proposed the motion-aware multi-tube masking strategy to compel the model into
effective long-range motion modeling. Extensive experiments conducted on three large-scale
prevalent benchmarks validated the effectiveness of our approach. The experimental results
showcased outstanding performance of our proposed Skeleton2vec,
achieving state-of-the-art results across multiple testing protocols.